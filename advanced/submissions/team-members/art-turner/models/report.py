"""Data models for multi-agent research reports.

This module defines the data structures for the advanced multi-agent workflow,
including subtopics, per-researcher findings, and the combined synthesis report.
"""

from typing import List, Optional
from datetime import datetime
from pydantic import BaseModel, Field


class Source(BaseModel):
    """Model for a source citation."""

    title: str = Field(..., description="Title of the source")
    url: str = Field(..., description="URL of the source")
    snippet: str = Field(..., description="Relevant excerpt from the source")
    score: Optional[float] = Field(None, description="Relevance score (0-1)")
    why_matters: Optional[str] = Field(
        None, description="Explanation of why this source is important"
    )


class KeyFinding(BaseModel):
    """Model for a key finding with citations."""

    finding: str = Field(..., description="The key finding or insight")
    citations: List[str] = Field(
        default_factory=list,
        description="List of source URLs supporting this finding"
    )


class Subtopic(BaseModel):
    """Model for a research subtopic generated by the Topic Splitter."""

    name: str = Field(..., description="Name/title of the subtopic")
    description: str = Field(..., description="Brief description of what to research")
    search_queries: List[str] = Field(
        default_factory=list,
        description="Suggested search queries for this subtopic"
    )


class SubtopicFindings(BaseModel):
    """Model for findings from a single researcher agent on one subtopic."""

    subtopic: str = Field(..., description="The subtopic that was researched")
    summary: str = Field(..., description="TL;DR summary of findings for this subtopic")
    key_insights: List[KeyFinding] = Field(
        default_factory=list,
        description="Key insights discovered for this subtopic"
    )
    sources: List[Source] = Field(
        default_factory=list,
        description="Sources found for this subtopic"
    )
    researcher_notes: Optional[str] = Field(
        None,
        description="Additional notes from the researcher about this subtopic"
    )


class CriticIssue(BaseModel):
    """Model for an issue found by the Critic Agent."""

    category: str = Field(
        ...,
        description="Issue category: factual_consistency, citation_accuracy, logical_coherence, completeness"
    )
    severity: str = Field(
        ...,
        description="Issue severity: minor, moderate, major"
    )
    description: str = Field(..., description="Description of the issue")
    location: str = Field(..., description="Where in the report the issue was found")
    suggestion: str = Field(..., description="Suggested fix for the issue")


class CriticReview(BaseModel):
    """Model for the Critic Agent's review of a report."""

    decision: str = Field(
        ...,
        description="Review decision: APPROVED or REVISION_NEEDED"
    )
    overall_score: int = Field(
        ...,
        description="Overall quality score (1-10)",
        ge=1,
        le=10
    )
    issues_found: List[CriticIssue] = Field(
        default_factory=list,
        description="List of issues found during review"
    )
    strengths: List[str] = Field(
        default_factory=list,
        description="Strengths of the report"
    )
    revision_instructions: str = Field(
        default="",
        description="Instructions for revision if needed"
    )
    iteration: int = Field(
        default=1,
        description="Which revision iteration this review is for"
    )


class MultiAgentReport(BaseModel):
    """
    Complete multi-agent research report.

    This model represents the final synthesized output from the multi-agent
    workflow, combining findings from multiple researcher agents into a
    coherent report with:
    - Executive Summary (≤150 words)
    - Key Insights by Subtopic
    - Conflicts or Gaps in Literature
    - Citations & Resource List
    """

    # Original topic
    topic: str = Field(..., description="The original research topic")

    # Subtopics identified by the Topic Splitter
    subtopics: List[str] = Field(
        default_factory=list,
        description="List of subtopics that were researched"
    )

    # Executive summary from the Synthesizer
    executive_summary: str = Field(
        ...,
        description="Executive summary (≤150 words)",
        max_length=1000  # Roughly 150 words
    )

    # Per-subtopic findings from each researcher
    subtopic_findings: List[SubtopicFindings] = Field(
        default_factory=list,
        description="Detailed findings for each subtopic"
    )

    # Overall key insights synthesized across all subtopics
    overall_insights: List[KeyFinding] = Field(
        default_factory=list,
        description="Key insights synthesized across all subtopics"
    )

    # Consensus points - where sources agree
    consensus_points: List[str] = Field(
        default_factory=list,
        description="Points where multiple sources/subtopics agree"
    )

    # Conflicts and gaps in the literature
    conflicts_and_gaps: str = Field(
        default="",
        description="Discussion of conflicts between sources and gaps in literature"
    )

    # All citations consolidated
    all_sources: List[Source] = Field(
        default_factory=list,
        description="All sources from all researchers"
    )

    # Top sources across all subtopics
    top_sources: List[Source] = Field(
        default_factory=list,
        description="Top 5 most relevant sources overall",
        max_length=5
    )

    # Critic review (added after synthesis)
    critic_review: Optional["CriticReview"] = Field(
        default=None,
        description="Review from the Critic Agent"
    )

    # Revision history
    revision_count: int = Field(
        default=0,
        description="Number of revisions made based on critic feedback"
    )

    def model_dump_summary(self) -> dict:
        """Return a summary version of the report."""
        return {
            "topic": self.topic,
            "num_subtopics": len(self.subtopics),
            "executive_summary": self.executive_summary[:200] + "..." if len(self.executive_summary) > 200 else self.executive_summary,
            "total_findings": sum(len(sf.key_insights) for sf in self.subtopic_findings),
            "total_sources": len(self.all_sources),
        }

    class Config:
        """Pydantic configuration."""
        json_schema_extra = {
            "example": {
                "topic": "Impact of artificial intelligence on healthcare",
                "subtopics": ["AI in diagnostics", "AI in drug discovery", "AI in patient care"],
                "executive_summary": "Artificial intelligence is transforming healthcare across multiple domains...",
                "subtopic_findings": [
                    {
                        "subtopic": "AI in diagnostics",
                        "summary": "AI shows promising results in medical imaging...",
                        "key_insights": [
                            {
                                "finding": "Deep learning outperforms radiologists in detecting certain cancers",
                                "citations": ["https://example.com/paper1"]
                            }
                        ],
                        "sources": []
                    }
                ],
                "overall_insights": [
                    {
                        "finding": "AI adoption in healthcare is accelerating rapidly",
                        "citations": ["https://example.com/paper1", "https://example.com/paper2"]
                    }
                ],
                "consensus_points": ["AI improves diagnostic accuracy", "Integration challenges remain"],
                "conflicts_and_gaps": "Sources disagree on regulatory timelines...",
                "all_sources": [],
                "top_sources": []
            }
        }
